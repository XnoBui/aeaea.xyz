<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AEAEA - Digital Fashion & Innovation Studio</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@200;300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/aeaea_company_website.css">
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="logo">
            <a href="#"><img src="images/aelogo_1.png" alt="AEAEA Logo"></a>
        </div>
        <div class="nav-links">
            <a href="#services">Services</a>
            <a href="#soma">Digital Humans</a>
            <a href="#fashion">Digital Fashion</a>
            <a href="#ar">AR</a>
            <a href="#metaverse">Metaverse</a>
            <a href="#contact">Contact</a>
        </div>
    </nav>

    <!-- Hero -->
    <section class="hero">
        <div id="container"></div>
        <div class="hero-content">
            <h1>Digital Innovation Studio</h1>
            <p>We are at the forefront of digital innovation, creating cutting-edge digital humans, virtual fashion, immersive AR experiences, and metaverse spaces</p>
        </div>
        <div class="scroll-indicator">‚Üì</div>
    </section>

    <!-- Services Overview -->
    <section id="services" class="services-overview">
        <div class="section-header">
            <h2>What We Do</h2>
            <p>We offer four specialized services that are shaping the digital future.</p>
        </div>
        
        <div class="services-grid">
            <div class="service-card">
                <div class="service-number">01</div>
                <h3>Digital Humans</h3>
                <p>SOMA - Professional digital humans for campaigns, content, and partnerships. Luna, Riven, and more.</p>
                <a href="#soma" class="service-link">Learn more ‚Üí</a>
            </div>
            
            <div class="service-card">
                <div class="service-number">02</div>
                <h3>Digital Fashion</h3>
                <p>Virtual clothing and accessories. From concept to 3D modeling. For games, metaverse, and social media.</p>
                <a href="#fashion" class="service-link">Learn more ‚Üí</a>
            </div>
            
            <div class="service-card">
                <div class="service-number">03</div>
                <h3>AR Experiences</h3>
                <p>Augmented reality filters, try-ons, and interactive experiences. Instagram, Snapchat, and custom apps.</p>
                <a href="#ar" class="service-link">Learn more ‚Üí</a>
            </div>
            
            <div class="service-card">
                <div class="service-number">04</div>
                <h3>Metaverse Spaces</h3>
                <p>Virtual worlds, showrooms, and event spaces. Spatial design for Decentraland, Roblox, and custom platforms.</p>
                <a href="#metaverse" class="service-link">Learn more ‚Üí</a>
            </div>
        </div>
    </section>

    <!-- SOMA Digital Humans -->
    <section id="soma" class="service-detail">
        <div class="service-content">
            <div class="service-info">
                <h3>SOMA Digital Humans</h3>
                <p>Our digital humans work like real talent. They create content, engage audiences, and represent brands. Each has their own personality, style, and growing fanbase.</p>
                <ul class="service-features">
                    <li>5 established digital humans with real followers</li>
                    <li>Fashion campaigns and brand partnerships</li>
                    <li>Music creation and performances</li>
                    <li>24/7 availability, no geographic limits</li>
                    <li>AI-powered conversations and content</li>
                </ul>
                <a href="https://soma.ai" class="service-link">Visit SOMA ‚Üí</a>
            </div>
            <div class="service-visual">SOMA</div>
        </div>
    </section>

    <!-- Digital Fashion -->
    <section id="fashion" class="service-detail">
        <div class="service-content">
            <div class="service-info">
                <h3>Digital Fashion</h3>
                <p>We design and create virtual clothing that exists purely in digital spaces. From haute couture to streetwear, our pieces can be worn in photos, videos, games, and virtual worlds.</p>
                <ul class="service-features">
                    <li>3D garment design and modeling</li>
                    <li>Virtual try-on technology</li>
                    <li>NFT fashion collections</li>
                    <li>Game-ready wearables</li>
                    <li>Social media fashion filters</li>
                </ul>
                <a href="#contact" class="service-link">Start a project ‚Üí</a>
            </div>
            <div class="service-visual">FASHION</div>
        </div>
    </section>

    <!-- AR Experiences -->
    <section id="ar" class="service-detail">
        <div class="service-content">
            <div class="service-info">
                <h3>AR Experiences</h3>
                <p>Augmented reality that bridges physical and digital. We create filters, effects, and interactive experiences that transform how people engage with brands and content.</p>
                <ul class="service-features">
                    <li>Instagram and Snapchat filters</li>
                    <li>Virtual try-on for products</li>
                    <li>Interactive AR campaigns</li>
                    <li>WebAR experiences</li>
                    <li>Custom AR applications</li>
                </ul>
                <a href="#contact" class="service-link">Create AR experience ‚Üí</a>
            </div>
            <div class="service-visual">AR</div>
        </div>
    </section>

    <!-- Metaverse Spaces -->
    <section id="metaverse" class="service-detail">
        <div class="service-content">
            <div class="service-info">
                <h3>Metaverse Spaces</h3>
                <p>Virtual environments where people gather, shop, and experience. We design and build spaces that feel alive, from intimate showrooms to massive event venues.</p>
                <ul class="service-features">
                    <li>Virtual showrooms and galleries</li>
                    <li>Event spaces and concert venues</li>
                    <li>Roblox and Decentraland builds</li>
                    <li>Custom virtual worlds</li>
                    <li>Spatial UX design</li>
                </ul>
                <a href="#contact" class="service-link">Build your space ‚Üí</a>
            </div>
            <div class="service-visual">META</div>
        </div>
    </section>

    <!-- Showcase -->
    <section class="showcase-section">
        <div class="section-header">
            <h2>Selected Work</h2>
        </div>
        <div class="showcase-grid">
            <div class="showcase-item">üì∏</div>
            <div class="showcase-item">üëó</div>
            <div class="showcase-item">üé≠</div>
            <div class="showcase-item">üåê</div>
            <div class="showcase-item">‚ú®</div>
            <div class="showcase-item">üéµ</div>
            <div class="showcase-item">üèõÔ∏è</div>
            <div class="showcase-item">üëÅÔ∏è</div>
        </div>
    </section>

    <!-- About -->
    <section class="about-section">
        <h2>About AEAEA</h2>
        <p>We are a digital innovation studio at the intersection of fashion, technology, and human expression.</p>
        <p>After years of R&D, we're excited to share our vision of digital humanity through practical applications.</p>
        
        <div class="team-info">
            <h3>YGILABS</h3>
            <p>Founded by a team with backgrounds in fashion design, interior design, and technology. We believe the future is both digital and deeply human.</p>
        </div>
    </section>

    <!-- Contact -->
    <section id="contact" class="contact-section">
        <div class="contact-content">
            <h2>Start a Project</h2>
            <div class="contact-info">
                <div class="contact-item">
                    <h4>General Inquiries</h4>
                    <p><a href="mailto:hello@aeaea.xyz">hello@aeaea.xyz</a></p>
                </div>
                <div class="contact-item">
                    <h4>SOMA Bookings</h4>
                    <p><a href="mailto:soma@aeaea.xyz">soma@aeaea.xyz</a></p>
                </div>
            </div>
            <p style="color: #666;">Contact us for project inquiries</p>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <p>¬© 2025 AEAEA by YGILABS. Creating the digital future.</p>
    </footer>

    <!-- Bottom Navigation -->
    <div class="bottom-nav">
        <a href="#services" class="bottom-nav-link">
            <span>Services</span>
        </a>
        <a href="#soma" class="bottom-nav-link">
            <span>Digital Humans</span>
        </a>
        <a href="#fashion" class="bottom-nav-link">
            <span>Digital Fashion</span>
        </a>
        <a href="#ar" class="bottom-nav-link">
            <span>AR</span>
        </a>
        <a href="#contact" class="bottom-nav-link">
            <span>Contact</span>
        </a>
    </div>
    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';

        let scene, camera, renderer, model, mixer, clock;
        let morphTargets = {};
        let blinkTimer = 0;
        let nextBlinkTime = Math.random() * 3 + 2;
        let isBlinking = false;
        let blinkDuration = 0.3; // Slower, more natural blink duration
        let currentBlinkTime = 0;
        let idleTime = 0; // For subtle idle animation
        
        // Enhanced animation variables
        let microMovementTime = 0;
        let saccadeTimer = 0;
        let nextSaccadeTime = Math.random() * 2 + 1;
        let currentSaccade = { x: 0, y: 0 };
        let targetSaccade = { x: 0, y: 0 };
        let saccadeProgress = 1;
        let breathingPhase = 0;
        let breathingIntensity = 1;
        let postureShiftTimer = 0;
        let nextPostureShift = Math.random() * 10 + 5;
        let currentPosture = { x: 0, y: 0, z: 0 };
        let targetPosture = { x: 0, y: 0, z: 0 };
        let postureProgress = 1;
        let blinkType = 'normal'; // normal, quick, slow, double
        let facialTwitchTimer = 0;
        let nextFacialTwitch = Math.random() * 5 + 3;
        let headNodTimer = 0;
        let nextHeadNod = Math.random() * 15 + 10;
        let isNodding = false;
        let nodProgress = 0;

        function init() {
            console.log('Initializing enhanced SOMA model viewer...');
            
            const container = document.getElementById('container');
            if (!container) {
                console.error('Container not found');
                return;
            }
            
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(35, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setClearColor(0x000000, 0);
            renderer.shadowMap.enabled = true;
            renderer.shadowMap.type = THREE.PCFSoftShadowMap;
            renderer.toneMapping = THREE.ACESFilmicToneMapping;
            renderer.toneMappingExposure = 1.2;
            
            container.appendChild(renderer.domElement);

            // Load the SOMA model
            const loader = new GLTFLoader();
            
            const possiblePaths = [
                './SOMA MODEL ANIMATION TEST.glb',
                'SOMA MODEL ANIMATION TEST.glb',
                './SOMA%20MODEL%20ANIMATION%20TEST.glb',
                'SOMA%20MODEL%20ANIMATION%20TEST.glb'
            ];
            
            let currentPathIndex = 0;
            
            function tryLoadModel() {
                if (currentPathIndex >= possiblePaths.length) {
                    console.error('Could not load SOMA model from any path');
                    return;
                }
                
                const currentPath = possiblePaths[currentPathIndex];
                console.log(`Trying to load SOMA model from: ${currentPath}`);
                
                loader.load(
                    currentPath,
                    function (gltf) {
                        console.log('SOMA model loaded successfully');
                        model = gltf.scene;
                        
                        // Position the model
                        model.position.set(0, -6.8, 0);
                        model.scale.set(7, 5, 7);
                        
                        // Setup enhanced model features
                        setupModelEnhancements(model);
                        
                        scene.add(model);
                        
                        // Setup animations if available
                        if (gltf.animations && gltf.animations.length > 0) {
                            mixer = new THREE.AnimationMixer(model);
                            gltf.animations.forEach((clip) => {
                                const action = mixer.clipAction(clip);
                                action.play();
                            });
                        }

                    },
                    function(progress) {
                        console.log('Loading progress:', (progress.loaded / progress.total * 100) + '%');
                    },
                    function (error) {
                        console.error(`Error loading model from ${currentPath}:`, error);
                        currentPathIndex++;
                        tryLoadModel();
                    }
                );
            }
            
            tryLoadModel();

            // Enhanced lighting setup for facial features
            setupLighting();

            // Position camera - fixed to prevent any zoom effect
            camera.position.set(0, 1.2, 2.5);
            camera.lookAt(0, 1.2, 0);
            camera.fov = 35; // Lock FOV
            camera.updateProjectionMatrix();

            // Animation clock
            clock = new THREE.Clock();

            animate();
        }

        function setupModelEnhancements(model) {
            model.traverse(function(child) {
                if (child.isMesh) {
                    child.castShadow = true;
                    child.receiveShadow = true;
                    
                    // Look for facial meshes and setup morphing
                    if (child.name.toLowerCase().includes('face') || 
                        child.name.toLowerCase().includes('head') ||
                        child.name.toLowerCase().includes('eye') ||
                        child.name.toLowerCase().includes('mouth') ||
                        child.name.toLowerCase().includes('brow')) {
                        
                        // Store eye meshes for tracking
                        if (child.name.toLowerCase().includes('eye')) {
                            eyeMeshes.push(child);
                            console.log('Found eye mesh for tracking:', child.name);
                        }
                        
                        // Create artificial morph targets for facial expressions
                        setupArtificialMorphTargets(child);
                    }
                    
                    // Enhance materials
                    if (child.material) {
                        const materials = Array.isArray(child.material) ? child.material : [child.material];
                        materials.forEach(material => {
                            if (material.isMeshStandardMaterial || material.isMeshPhysicalMaterial) {
                                material.metalness = material.metalness || 0.1;
                                material.roughness = material.roughness || 0.4;
                                material.envMapIntensity = 1.2;
                                
                                // Enhance skin materials
                                if (material.name && material.name.toLowerCase().includes('skin')) {
                                    material.roughness = 0.6;
                                    material.metalness = 0.0;
                                    material.transparent = true;
                                    material.opacity = 0.95;
                                }
                            }
                        });
                    }
                }
            });
        }

        function setupArtificialMorphTargets(mesh) {
            morphTargets[mesh.uuid] = {
                mesh: mesh,
                originalScale: mesh.scale.clone(),
                originalPosition: mesh.position.clone(),
                originalRotation: mesh.rotation.clone()
            };
        }

        function setupLighting() {
            // Key light for main illumination
            const keyLight = new THREE.DirectionalLight(0xffffff, 3.0);
            keyLight.position.set(2, 4, 3);
            keyLight.castShadow = true;
            keyLight.shadow.mapSize.width = 2048;
            keyLight.shadow.mapSize.height = 2048;
            scene.add(keyLight);

            // Fill light to soften shadows
            const fillLight = new THREE.DirectionalLight(0xfff8e1, 1.5);
            fillLight.position.set(-2, 2, 2);
            scene.add(fillLight);

            // Rim light for depth
            const rimLight = new THREE.DirectionalLight(0xe3f2fd, 2.0);
            rimLight.position.set(0, 3, -2);
            scene.add(rimLight);

            // Soft ambient light
            const ambientLight = new THREE.AmbientLight(0xf5f5f5, 0.8);
            scene.add(ambientLight);

            // Focused face light
            const faceLight = new THREE.SpotLight(0xffffff, 2.5, 8, Math.PI / 8, 0.2);
            faceLight.position.set(0, 4, 1.5);
            faceLight.target.position.set(0, 0, 0);
            scene.add(faceLight);
            scene.add(faceLight.target);
        }


        function handleBlinking(delta) {
            blinkTimer += delta;

            if (!isBlinking && blinkTimer >= nextBlinkTime) {
                // Start blink with natural timing variation
                isBlinking = true;
                currentBlinkTime = 0;
                blinkTimer = 0;
                nextBlinkTime = Math.random() * 3 + 2.5; // Natural blink interval 2.5-5.5 seconds
            }

            if (isBlinking) {
                currentBlinkTime += delta;
                
                // Professional blink curve - more natural easing
                let blinkProgress;
                const halfDuration = blinkDuration / 2;
                
                if (currentBlinkTime < halfDuration) {
                    // Ease-in-out for closing phase
                    const t = currentBlinkTime / halfDuration;
                    blinkProgress = t * t * (3 - 2 * t); // Smooth step function
                } else if (currentBlinkTime < blinkDuration) {
                    // Ease-in-out for opening phase
                    const t = (currentBlinkTime - halfDuration) / halfDuration;
                    blinkProgress = 1 - (t * t * (3 - 2 * t));
                } else {
                    blinkProgress = 0;
                    isBlinking = false;
                }

                // Apply professional blink with smooth integration
                const blinkCloseFactor = blinkProgress * 0.25; // Subtle blink intensity
                
                // Store blink factor for use in updateEyeTracking
                window.currentBlinkFactor = blinkCloseFactor;
                
            } else {
                window.currentBlinkFactor = 0;
            }
        }

        function animate() {
            requestAnimationFrame(animate);
            
            const delta = clock.getDelta();
            
            // Update animations
            if (mixer) {
                mixer.update(delta);
            }
            
            // Handle natural blinking
            handleBlinking(delta);
            
            // Update eye tracking with saccades
            updateEyeTracking();
            handleSaccades(delta);
            
            // Update all animation timers
            idleTime += delta;
            microMovementTime += delta;
            
            if (model) {
                // Smoothly update head rotation towards the target
                currentHeadRotation.x = lerp(currentHeadRotation.x, targetHeadRotation.x, headRotationSpeed);
                currentHeadRotation.y = lerp(currentHeadRotation.y, targetHeadRotation.y, headRotationSpeed);
                currentHeadRotation.z = lerp(currentHeadRotation.z, targetHeadRotation.z, headRotationSpeed * 0.5);

                // Apply mouse-driven head rotation
                model.rotation.x = currentHeadRotation.x;
                model.rotation.y = currentHeadRotation.y;
                model.rotation.z = currentHeadRotation.z;
            }
            
            renderer.render(scene, camera);
        }
        
        // Handle saccadic eye movements
        function handleSaccades(delta) {
            saccadeTimer += delta;
            
            if (saccadeProgress >= 1 && saccadeTimer >= nextSaccadeTime) {
                // Generate new saccade target
                targetSaccade.x = (Math.random() - 0.5) * 0.15;
                targetSaccade.y = (Math.random() - 0.5) * 0.1;
                saccadeProgress = 0;
                saccadeTimer = 0;
                nextSaccadeTime = Math.random() * 2 + 0.5;
            }
            
            if (saccadeProgress < 1) {
                // Quick saccade movement
                saccadeProgress = Math.min(1, saccadeProgress + delta * 8);
                const t = saccadeProgress;
                currentSaccade.x = lerp(currentSaccade.x, targetSaccade.x, t);
                currentSaccade.y = lerp(currentSaccade.y, targetSaccade.y, t);
            }
        }
        
        // Handle posture shifts
        function handlePostureShifts(delta) {
            postureShiftTimer += delta;
            
            if (postureProgress >= 1 && postureShiftTimer >= nextPostureShift) {
                // Generate subtle posture adjustment
                targetPosture.x = (Math.random() - 0.5) * 0.02;
                targetPosture.y = (Math.random() - 0.5) * 0.03;
                targetPosture.z = (Math.random() - 0.5) * 0.01;
                postureProgress = 0;
                postureShiftTimer = 0;
                nextPostureShift = Math.random() * 15 + 10;
            }
            
            if (postureProgress < 1) {
                // Slow posture transition
                postureProgress = Math.min(1, postureProgress + delta * 0.3);
                const t = postureProgress * postureProgress * (3 - 2 * postureProgress);
                currentPosture.x = lerp(currentPosture.x, targetPosture.x, t);
                currentPosture.y = lerp(currentPosture.y, targetPosture.y, t);
                currentPosture.z = lerp(currentPosture.z, targetPosture.z, t);
            }
        }
        
        // Handle head nods
        function handleHeadNods(delta) {
            headNodTimer += delta;
            
            if (!isNodding && headNodTimer >= nextHeadNod) {
                isNodding = true;
                nodProgress = 0;
                headNodTimer = 0;
                nextHeadNod = Math.random() * 20 + 15;
            }
            
            if (isNodding) {
                nodProgress += delta * 2;
                if (nodProgress < 1) {
                    // Subtle nod animation
                    const nodAmount = Math.sin(nodProgress * Math.PI) * 0.03;
                    currentPosture.x += nodAmount;
                } else {
                    isNodding = false;
                }
            }
        }
        
        // Handle facial twitches
        function handleFacialTwitches(delta) {
            facialTwitchTimer += delta;
            
            if (facialTwitchTimer >= nextFacialTwitch) {
                facialTwitchTimer = 0;
                nextFacialTwitch = Math.random() * 8 + 5;
                
                // Apply subtle facial muscle movements
                model.traverse(function(child) {
                    if (child.isMesh && morphTargets[child.uuid]) {
                        const target = morphTargets[child.uuid];
                        
                        // Subtle eyebrow twitch
                        if (child.name.toLowerCase().includes('brow')) {
                            const twitchAmount = (Math.random() - 0.5) * 0.01;
                            child.position.y = target.originalPosition.y + twitchAmount;
                            
                            // Reset after a short time
                            setTimeout(() => {
                                child.position.y = target.originalPosition.y;
                            }, 200);
                        }
                        
                        // Subtle mouth corner movement
                        if (child.name.toLowerCase().includes('mouth') || 
                            child.name.toLowerCase().includes('lip')) {
                            const twitchX = (Math.random() - 0.5) * 0.005;
                            child.position.x = target.originalPosition.x + twitchX;
                            
                            setTimeout(() => {
                                child.position.x = target.originalPosition.x;
                            }, 300);
                        }
                    }
                });
            }
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // Optimized mouse tracking variables (Holoworld best practices)
        let mousePosition = { x: 0, y: 0 };
        let eyeMeshes = [];
        let targetMousePosition = { x: 0, y: 0 };
        let currentMousePosition = { x: 0, y: 0 };
        let targetHeadRotation = { x: 0, y: 0, z: 0 };
        let currentHeadRotation = { x: 0, y: 0, z: 0 };
        let targetEyeRotation = { x: 0, y: 0 };
        let currentEyeRotation = { x: 0, y: 0 };
        let smoothMousePosition = { x: 0, y: 0 };
        let eyeVelocity = { x: 0, y: 0 };
        
        // Natural movement parameters (refined for realistic behavior)
        const mouseSmoothingFactor = 0.08; // Slower for more natural movement
        const headRotationSpeed = 0.05; // Much slower, more realistic head movement
        const eyeTrackingSpeed = 0.15; // Natural eye speed
        const maxHeadRotation = { x: 0.15, y: 0.25, z: 0.05 }; // Increased range for visibility
        const maxEyeRotation = { x: 0.15, y: 0.25 }; // Natural eye movement range
        const mouseInfluence = 0.7; // Reduce mouse influence for subtler movement

        function updateEyeTracking() {
            if (!model || eyeMeshes.length === 0) return;
            
            // Professional smooth mouse position filtering
            smoothMousePosition.x += (mousePosition.x - smoothMousePosition.x) * 0.25; // mouseSmoothing
            smoothMousePosition.y += (mousePosition.y - smoothMousePosition.y) * 0.25; // mouseSmoothing

            // Enhanced target eye rotation with proper vertical tracking
            targetEyeRotation.x = -smoothMousePosition.y * 0.4; // maxEyeRotation.x
            targetEyeRotation.y = smoothMousePosition.x * 0.5;  // maxEyeRotation.y

            // Apply dead zone to prevent micro-movements
            const deltaX = targetEyeRotation.x - currentEyeRotation.x;
            const deltaY = targetEyeRotation.y - currentEyeRotation.y;
            
            if (Math.abs(deltaX) > 0.015 || Math.abs(deltaY) > 0.015) { // deadZone
                // Calculate velocity-based acceleration for natural movement
                eyeVelocity.x += deltaX * 0.12; // eyeAcceleration
                eyeVelocity.y += deltaY * 0.12; // eyeAcceleration
                
                // Apply damping to velocity for smooth deceleration
                eyeVelocity.x *= 0.88; // eyeDamping
                eyeVelocity.y *= 0.88; // eyeDamping
                
                // Update current eye rotation with velocity
                currentEyeRotation.x += eyeVelocity.x;
                currentEyeRotation.y += eyeVelocity.y;
                
                // Smooth interpolation towards target for final precision
                currentEyeRotation.x += (targetEyeRotation.x - currentEyeRotation.x) * 0.18; // eyeTrackingSpeed
                currentEyeRotation.y += (targetEyeRotation.y - currentEyeRotation.y) * 0.18; // eyeTrackingSpeed
            }

            // Apply eye tracking to all eye meshes with enhanced vertical movement
            eyeMeshes.forEach(eyeMesh => {
                if (morphTargets[eyeMesh.uuid]) {
                    const target = morphTargets[eyeMesh.uuid];
                    
                    // Get current facial expression and blink values
                    const eyeOpenness = 0.2; // Default value from applyDefaultExpression
                    const closeFactor = 1 - eyeOpenness;
                    const blinkFactor = window.currentBlinkFactor || 0;
                    const totalCloseFactor = closeFactor + blinkFactor;
                    
                    // Enhanced eye tracking with proper vertical movement physics
                    const finalRotationX = target.originalRotation.x + currentEyeRotation.x + (totalCloseFactor * 0.06);
                    const finalRotationY = target.originalRotation.y + currentEyeRotation.y;
                    const finalRotationZ = target.originalRotation.z + (currentEyeRotation.x * 0.1); // Subtle Z rotation for realism
                    
                    // Professional smooth transition with adaptive speed
                    const rotationDeltaX = finalRotationX - eyeMesh.rotation.x;
                    const rotationDeltaY = finalRotationY - eyeMesh.rotation.y;
                    const rotationDeltaZ = finalRotationZ - eyeMesh.rotation.z;
                    const rotationDistance = Math.sqrt(rotationDeltaX * rotationDeltaX + rotationDeltaY * rotationDeltaY + rotationDeltaZ * rotationDeltaZ);
                    
                    // Adaptive smoothing - faster for larger movements, slower for precision
                    const adaptiveSpeed = Math.min(0.4, 0.15 + rotationDistance * 2);
                    
                    eyeMesh.rotation.x += rotationDeltaX * adaptiveSpeed;
                    eyeMesh.rotation.y += rotationDeltaY * adaptiveSpeed;
                    eyeMesh.rotation.z += rotationDeltaZ * adaptiveSpeed;
                    
                    // Enhanced eyelid position with vertical tracking influence
                    const upperLidInfluence = Math.max(0, currentEyeRotation.x) * 0.025; // Eyelid lowers when looking down
                    const lowerLidInfluence = Math.min(0, currentEyeRotation.x) * 0.015; // Eyelid raises slightly when looking up

                    const targetPositionY = target.originalPosition.y - totalCloseFactor * 0.016 - upperLidInfluence + lowerLidInfluence;
                    const positionDelta = targetPositionY - eyeMesh.position.y;
                    eyeMesh.position.y += positionDelta * 0.3;
                    
                    // Subtle position adjustments for realistic eye movement
                    const targetPositionX = target.originalPosition.x + currentEyeRotation.y * 0.004;
                    const targetPositionZ = target.originalPosition.z + currentEyeRotation.x * 0.003;
                    eyeMesh.position.x += (targetPositionX - eyeMesh.position.x) * 0.2;
                    eyeMesh.position.z += (targetPositionZ - eyeMesh.position.z) * 0.2;
                    
                    // Enhanced scale handling - NO vertical squinting
                    eyeMesh.visible = true;
                    let targetScaleY = target.originalScale.y;
                    let targetScaleX = target.originalScale.x;
                    
                    // Only apply scale reduction for actual eye closure (blinking), not vertical tracking
                    if (eyeOpenness < 0.3 || blinkFactor > 0.1) {
                        const scaleReduction = Math.max(totalCloseFactor * 0.15, 0);
                        targetScaleY = target.originalScale.y * (1 - scaleReduction);
                        targetScaleX = target.originalScale.x * (1 - scaleReduction * 0.3);
                    }
                    
                    const scaleDeltaY = targetScaleY - eyeMesh.scale.y;
                    const scaleDeltaX = targetScaleX - eyeMesh.scale.x;
                    eyeMesh.scale.y += scaleDeltaY * 0.25;
                    eyeMesh.scale.x += scaleDeltaX * 0.25;
                    
                    // Ensure minimum scale to prevent eye disappearing - increased minimum
                    eyeMesh.scale.y = Math.max(eyeMesh.scale.y, target.originalScale.y * 0.8); // Increased from 0.3
                    eyeMesh.scale.x = Math.max(eyeMesh.scale.x, target.originalScale.x * 0.9); // Increased from 0.7
                }
            });
        }
        
        // Linear interpolation helper function (from Holoworld)
        function lerp(start, end, factor) {
            return start + (end - start) * factor;
        }

        function onMouseMove(event) {
            // Calculate normalized mouse position (-1 to 1)
            const rawX = (event.clientX / window.innerWidth) * 2 - 1;
            const rawY = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // Apply mouse influence for subtler movement
            mousePosition.x = rawX * mouseInfluence;
            mousePosition.y = rawY * mouseInfluence;
            
            // Update target mouse position with smooth clamping
            targetMousePosition.x = Math.max(-1, Math.min(1, mousePosition.x));
            targetMousePosition.y = Math.max(-1, Math.min(1, mousePosition.y));
            
            if (model) {
                // Calculate target head rotation with easing curve for natural movement
                // Apply non-linear transformation for more natural feel
                const easedX = Math.sign(targetMousePosition.x) * Math.pow(Math.abs(targetMousePosition.x), 1.5);
                const easedY = Math.sign(targetMousePosition.y) * Math.pow(Math.abs(targetMousePosition.y), 1.5);
                
                targetHeadRotation.y = easedX * maxHeadRotation.y;
                targetHeadRotation.x = easedY * maxHeadRotation.x * 0.7; // Reduce vertical movement
                targetHeadRotation.z = easedY * easedX * maxHeadRotation.z * 0.5; // Subtle tilt
                
                // Smooth head rotation interpolation with natural speed
                currentHeadRotation.x = lerp(currentHeadRotation.x, targetHeadRotation.x, headRotationSpeed);
                currentHeadRotation.y = lerp(currentHeadRotation.y, targetHeadRotation.y, headRotationSpeed);
                currentHeadRotation.z = lerp(currentHeadRotation.z, targetHeadRotation.z, headRotationSpeed * 0.5);
                
                // Head rotation is now handled in the animate function with all combined movements
                // Store the target values for use in animate
            }
        }

        window.addEventListener('resize', onWindowResize, false);
        document.addEventListener('mousemove', onMouseMove, false);
        
        // Add mouse leave handler to reset to neutral position
        document.addEventListener('mouseleave', function() {
            targetMousePosition.x = 0;
            targetMousePosition.y = 0;
        });

        // Initialize when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', init);
        } else {
            init();
        }
    </script>
</body>
</html>
